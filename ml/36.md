# 第三十六章 泰坦尼克数据集 KMeans

> 原文：[K-Means with Titanic Dataset](https://pythonprogramming.net/k-means-titanic-dataset-machine-learning-tutorial/)

> 译者：[飞龙](https://github.com/wizardforcel)

> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

欢迎阅读第三十六篇教程，另一篇话题为聚类的教程。

之前的教程中，我们涉及了如何处理非数值的数据，这里我们打算实际对泰坦尼克数据集应用 KMeans 算法。KMeans 算法是个扁平聚类算法，也就是说我们需要告诉机器一件事情，应该有多少个簇。我们打算告诉算法有两个分组，之后我们让机器寻找幸存者和遇难者，基于它选取的这两个分组。

我们的代码为：

```py
#https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls
import matplotlib.pyplot as plt
from matplotlib import style
style.use('ggplot')
import numpy as np
from sklearn.cluster import KMeans
from sklearn import preprocessing
import pandas as pd

'''
Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)
survival Survival (0 = No; 1 = Yes)
name Name
sex Sex
age Age
sibsp Number of Siblings/Spouses Aboard
parch Number of Parents/Children Aboard
ticket Ticket Number
fare Passenger Fare (British pound)
cabin Cabin
embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
boat Lifeboat
body Body Identification Number
home.dest Home/Destination
'''

df = pd.read_excel('titanic.xls')
#print(df.head())
df.drop(['body','name'], 1, inplace=True)
df.convert_objects(convert_numeric=True)
df.fillna(0, inplace=True)
#print(df.head())

def handle_non_numerical_data(df):
    columns = df.columns.values

    for column in columns:
        text_digit_vals = {}
        def convert_to_int(val):
            return text_digit_vals[val]

        if df[column].dtype != np.int64 and df[column].dtype != np.float64:
            column_contents = df[column].values.tolist()
            unique_elements = set(column_contents)
            x = 0
            for unique in unique_elements:
                if unique not in text_digit_vals:
                    text_digit_vals[unique] = x
                    x+=1

            df[column] = list(map(convert_to_int, df[column]))

    return df

df = handle_non_numerical_data(df)
```

这里，我们可以立即执行聚类：

```py
X = np.array(df.drop(['survived'], 1).astype(float))
y = np.array(df['survived'])

clf = KMeans(n_clusters=2)
clf.fit(X)
```

好的，现在让我们看看，是否分组互相匹配。你可以注意，这里，幸存者是 0，遇难者是 1。对于聚类算法，机器会寻找簇，但是会给簇分配任意标签，以便寻找它们。因此，幸存者的分组可能是 0 或者 1，取决于随机度。因此，如果你的一致性是 30% 或者 70%，那么你的模型准确度是 70%。让我们看看吧：

```py
correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = clf.predict(predict_me)
    if prediction[0] == y[i]:
        correct += 1

print(correct/len(X))
# 0.4957983193277311
```

准确度是 49% ~ 51%，不是很好。还记得几篇教程之前，预处理的事情吗？当我们之前使用的时候，看起来不是很重要，但是这里呢？

```py
X = np.array(df.drop(['survived'], 1).astype(float))
X = preprocessing.scale(X)
y = np.array(df['survived'])

clf = KMeans(n_clusters=2)
clf.fit(X)

correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = clf.predict(predict_me)
    if prediction[0] == y[i]:
        correct += 1

print(correct/len(X))
# 0.7081741787624141
```

预处理看起来很重要。预处理的目的是把你的数据放到 -1 ~ 1 的范围内，这可以使事情更好。我从来没有见过预处理产生很大的负面影响，它至少不会有什么影响，但是这里产生了非常大的正面影响。

好奇的是，我想知道上不上船对它影响多大。我看到机器将人们划分为上船和不上船的。我们可以看到，添加`df.drop(['boat'], 1, inplace=True)`是否会有很大影响。

```
0.6844919786096256
```

并不是很重要，但是有轻微的影响。那么性别呢？你知道这个数据实际上有两个分类：男性和女性。可能这就是它的主要发现？现在我们尝试`df.drop(['sex'], 1, inplace=True)`。

```
0.6982429335370511
```

也不是很重要。

目前的完整代码：

```py
#https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls
import matplotlib.pyplot as plt
from matplotlib import style
style.use('ggplot')
import numpy as np
from sklearn.cluster import KMeans
from sklearn import preprocessing
import pandas as pd

'''
Pclass Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)
survival Survival (0 = No; 1 = Yes)
name Name
sex Sex
age Age
sibsp Number of Siblings/Spouses Aboard
parch Number of Parents/Children Aboard
ticket Ticket Number
fare Passenger Fare (British pound)
cabin Cabin
embarked Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
boat Lifeboat
body Body Identification Number
home.dest Home/Destination
'''

df = pd.read_excel('titanic.xls')
#print(df.head())
df.drop(['body','name'], 1, inplace=True)
df.convert_objects(convert_numeric=True)
df.fillna(0, inplace=True)
#print(df.head())

def handle_non_numerical_data(df):
    columns = df.columns.values

    for column in columns:
        text_digit_vals = {}
        def convert_to_int(val):
            return text_digit_vals[val]

        if df[column].dtype != np.int64 and df[column].dtype != np.float64:
            column_contents = df[column].values.tolist()
            unique_elements = set(column_contents)
            x = 0
            for unique in unique_elements:
                if unique not in text_digit_vals:
                    text_digit_vals[unique] = x
                    x+=1

            df[column] = list(map(convert_to_int, df[column]))

    return df

df = handle_non_numerical_data(df)


df.drop(['sex','boat'], 1, inplace=True)
X = np.array(df.drop(['survived'], 1).astype(float))
X = preprocessing.scale(X)
y = np.array(df['survived'])

clf = KMeans(n_clusters=2)
clf.fit(X)

correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = clf.predict(predict_me)
    if prediction[0] == y[i]:
        correct += 1

print(correct/len(X))
```

对我来说，这个聚类算法看似自动将这些人归类为幸存者和遇难者。真实有趣。我们没有过多判断，机器认为为什么选取这些分组，但是它们似乎和幸存者有很高的相关度。

下一篇教程中，我们打算进一步，从零创建我们自己的 KMeans 算法。
