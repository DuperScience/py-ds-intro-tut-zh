# 第四十五章 深度学习和 TensorFlow 简介

> 原文：[Introduction to Deep Learning with TensorFlow](https://pythonprogramming.net/tensorflow-introduction-machine-learning-tutorial/)

> 译者：[飞龙](https://github.com/wizardforcel)

> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

欢迎阅读深度学习与神经网络和 TensorFlow 的第二部分，以及机器学习教程系列的第 44 部分。 在本教程中，我们将介绍一些关于 TensorFlow 的基础知识，以及如何开始使用它。

像 TensorFlow 和 Theano 这样的库不仅仅是深入学习库，它们是**用于**深入学习的库。 他们实际上只是数值处理库，就像 Numpy 一样。 然而，不同的是，像 TensorFlow 这样的软件包使我们能够以高效率执行特定的机器学习数值处理操作，如巨大的矩阵上的求导。 我们也可以轻松地在 CPU 内核，GPU 内核或甚至多个 GPU 等多个设备上分布式处理。 但这不是全部！ 我们甚至可以在具有 TensorFlow 的分布式计算机网络上分发计算。 所以，虽然 TensorFlow 主要是与机器学习一起使用，但它实际上在其他领域也有使用，因为它真的只是一个庞大的数组操作库。

什么是张量（tensor）？ 到目前为止，在机器学习系列中，我们主要使用向量（numpy 数组），张量可以是一个向量。 最简单的说，一个张量是一个类似数组的对象，正如你所看到的，一个数组可以容纳你的矩阵，你的向量，甚至一个标量。

在这一点上，我们只需要将机器学习问题转化为张量函数，这可以用每一个 ML 算法来实现。 考虑神经网络。 神经网络能够分解成什么？

我们有数据（`X`），权重（`w`）和阈值（`t`）。 所有这些都是张量嘛？ `X`是数据集（一个数组），所以这是一个张量。 权重也是一组权重值，所以它们也是张量。阈值？ 与权重相同。 因此，我们的神经网络确实是`X`，`w`和``t或`f(Xwt)`的函数，所以我们准备完全了，当然可以使用 TensorFlow，但是如何呢？

TensorFlow 的工作方式是，首先定义和描述我们的抽象模型，然后在我们准备好的时候，在会话（session）中成为现实。 在 TensorFlow 术语中，该模型的描述是所谓的“计算图形”。 我们来玩一个简单的例子。 首先，我们来构建图：

```py
import tensorflow as tf

# creates nodes in a graph
# "construction phase"
x1 = tf.constant(5)
x2 = tf.constant(6)
```

所以我们有了一些值。现在，我们可以用这些值做一些事情，例如相乘：

```py
result = tf.mul(x1,x2)
print(result)
```

要注意输出仍然是个抽象的张量。没有运行实际计算，只能创建操作。我们的计算图中的每个操作或“op”都是图中的“节点”。

要真正看到结果，我们需要运行会话。 一般来说，你首先构建图形，然后“启动”图形：

```py
# defines our session and launches graph
sess = tf.Session()
# runs result
print(sess.run(result))
```

我们也可以将会话的输出赋给变量：

```py
output = sess.run(result)
print(output)
```

当你完成了一个会话是，你需要关闭它，来释放所使用的资源。

```py
sess.close()
```

关闭之后，你仍然可以引用`output`变量，但是你不能这样做了：

```py
sess.run(result)
```

这会返回错误另一个选项就是利用 Python 的`with`语句：

```py
with tf.Session() as sess:
    output = sess.run(result)
    print(output)
```

如果你不熟悉这些操作，它在这些语句所在的代码块中使用会话，然后在完成后自动关闭会话，和使用`with`语句打开文件的方法相同。

你还可以在多个设备上使用 TensorFlow，甚至可以使用多台分布式机器。 在特定 GPU 上运行某些计算的示例是：

```py
with tf.Session() as sess:
  with tf.device("/gpu:1"):
    matrix1 = tf.constant([[3., 3.]])
    matrix2 = tf.constant([[2.],[2.]])
    product = tf.matmul(matrix1, matrix2)
```

代码来自：[TensorFlow 文档](https://www.tensorflow.org/versions/r0.9/get_started/basic_usage.html#overview)。`tf.matmul`是矩阵乘法函数。

上述代码将在第二个系统 GPU 上运行计算。 如果你安装了 CPU 版本，那么这不是一个选项，但是你仍然应该意识到这个可能性。 TensorFlow 的 GPU 版本要求正确设置 CUDA（以及需要支持 CUDA 的 GPU）。 我有几个支持 CUDA 的 GPU，并希望最终能够充分使用它们，但这要等到以后了！

现在我们已经有了 TensorFlow 的基础知识了，下一个教程中我会邀请你，创建一个深度神经网络的“兔子洞”。 如果你需要安装 TensorFlow，如果你在 Mac 或 Linux 上，安装过程非常简单。 在 Windows 上，也不是很麻烦。 下一个教程是可选的，它只是用于在 Windows 机器上安装 TensorFlow。
