# 第三章 回归 - 特征和标签

> 原文：[Regression - Intro and Data](https://pythonprogramming.net/features-labels-machine-learning-tutorial/)

> 译者：[飞龙](https://github.com/wizardforcel)

> 协议：[CC BY-NC-SA 4.0](http://creativecommons.org/licenses/by-nc-sa/4.0/)

基于上一篇机器学习回归教程，我们将要对我们的股票价格数据执行回归。目前的代码：

```py
import quandl
import pandas as pd

df = quandl.get("WIKI/GOOGL")
df = df[['Adj. Open',  'Adj. High',  'Adj. Low',  'Adj. Close', 'Adj. Volume']]
df['HL_PCT'] = (df['Adj. High'] - df['Adj. Low']) / df['Adj. Close'] * 100.0
df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0
df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]
print(df.head())
```

这里我们已经获取了数据，判断出有价值的数据，并通过操作创建了一些。我们现在已经准备好使用回归开始机器学习的过程。首先，我们需要一些更多的导入。所有的导入是：

```py
import quandl, math
import numpy as np
import pandas as pd
from sklearn import preprocessing, cross_validation, svm
from sklearn.linear_model import LinearRegression
```

我们会使用`numpy`模块来将数据转换为 NumPy 数组，它是 Sklearn 的预期。我们在用到`preprocessing `和`cross_validation `时，会深入谈论他们，但是预处理是用于在机器学习之前，对数据清洗和缩放的模块。交叉验证在测试阶段使用。最后，我们也从 Sklearn 导入了`LinearRegression`算法，以及`svm`。它们用作我们的机器学习算法来展示结果。

这里，我们已经获取了我们认为有用的数据。真实的机器学习如何工作呢？使用监督式学习，你需要特征和标签。特征就是描述性属性，标签就是你尝试预测的结果。另一个常见的回归示例就是尝试为某个人预测保险的保费。保险公司会收集你的年龄、驾驶违规行为、公共犯罪记录，以及你的信用评分。公司会使用老客户，获取数据，并得出应该给客户的“理想保费”，或者如果他们觉得有利可图的话，他们会使用实际使用的客户。

所以，对于训练机器学习分类器来说，特征是客户属性，标签是和这些属性相关的保费。

我们这里，什么是特征和标签呢？我们尝试预测价格，所以价格就是标签？如果这样，什么是特征呢？对于预测我们的价格来说，我们的标签，就是我们打算预测的东西，实际上是未来价格。这样，我们的特征实际上是：当前价格、HL 百分比和百分比变化。标签价格是未来某个点的价格。让我们继续添加新的行：

```py
forecast_col = 'Adj. Close'
df.fillna(value=-99999, inplace=True)
forecast_out = int(math.ceil(0.01 * len(df)))
```

这里，我们定义了预测列，之后我们将任何 NaN 数据填充为 -99999。对于如何处理缺失数据，你有一些选择，你不能仅仅将 NaN（不是数值）数据点传给机器学习分类西，你需要处理它。一个主流选项就是将缺失值填充为 -99999。在许多机器学习分类器中，会将其是被为离群点。你也可以仅仅丢弃包含缺失值的所有特征或标签，但是这样你可能会丢掉大量的数据。

真实世界中，许多数据集都很混乱。多数股价或成交量数据都很干净，很少有缺失数据，但是许多数据集会有大量缺失数据。我见过一些数据集，大量的行含有缺失数据。你并不一定想要失去所有不错的数据，如果你的样例数据有一些缺失，你可能会猜测真实世界的用例也有一些缺失。你需要训练、测试并依赖相同数据，以及数据的特征。

最后，我们定义我们需要预测的东西。许多情况下，就像尝试预测客户的保费的案例中，你仅仅需要一个数字，但是对于预测来说，你需要预测指定数量的数据点。我们假设我们打算预测数据集整个长度的 1%。因此，如果我们的数据是 100 天的股票价格，我们需要能够预测未来一天的价格。选择你想要的那个。如果你只是尝试预测明天的价格，你应该选取一天之后的数据，而且也只能一天之后的数据。如果你打算预测 10 天，我们可以为每一天生成一个预测。

我们这里，我们决定了，特征是一系列当前值，标签是未来的价格，其中未来是数据集整个长度的 1%。我们假设所有当前列都是我们的特征，所以我们使用一个简单的 Pnadas 操作添加一个新的列：

```py
df['label'] = df[forecast_col].shift(-forecast_out)
```

现在我们拥有了数据，包含特征和标签。下面我们在实际运行任何东西之前，我们需要做一些预处理和最终步骤，我们在下一篇教程会关注。
